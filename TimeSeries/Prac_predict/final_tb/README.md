## 时间序列预测结果

总共汇报四种配置的结果：
- raw：原始数据
- d1：执行$n=1.75, L=5$降噪算法
- sub6：执行降采样因子$r=6$的降采样算法
- d1_sub6：先执行降噪算法再执行降采样算法

### 结果文件结构
**PPT上，最好展示"Red", "Violet", "Yellow"三个通道的预测结果。**
- 目录概览（仅解释含义，不含执行说明）：
```
Prac_predict/final_tb/
├── README.md                  # 本文件，汇总各配置含义与目录指引
├── plot_all.py                # 批量预测脚本（raw/d1 八通道，含日志输出）
├── raw/                       # 原始数据上训练/预测的结果
│   ├── cont/                  # 按“cont”方案（见 raw/cont/config.md）对每个通道单独预测的输出
│   │   ├── config.md          # 说明 cont 的起始索引、时间轴等设置
│   │   ├── data_<Channel>.npy # 各通道预测数据
│   │   ├── data_<Channel>.log # 各通道预测日志
│   │   └── data_<Channel>.svg # 各通道预测图
│   └── 本征/                  # “本征”= 仅用当前模型与当前测试集做单次示例预测
│       ├── config.md          # 起始索引等说明（start_idx=20，对应第21点）
│       └── data_<Channel>.svg # 各通道预测图
├── d1/                        # 对应 d1（n=1.75, L=5 降噪后训练/预测）的结果
│   ├── cont/                  # 按 d1/cont/config.md 的连续单通道预测输出
│   │   ├── config.md          # 说明 cont 的起始索引、时间轴等设置
│   │   ├── data_<Channel>.npy # 各通道预测数据
│   │   ├── data_<Channel>.log # 各通道预测日志
│   │   └── data_<Channel>.svg # 各通道预测图
│   └── 本征/                  # d1 模型的单次示例预测（“本征”同上含义）
│       ├── config.md          # 起始索引等说明（start_idx=20，对应第21点）
│       └── data_<Channel>.svg # 各通道预测图
├── sub6/                      # 仅降采样 (r=6) 场景的结果
│   └── off1/                  # 起始偏移off1的预测结果
│       ├── config.md         # 说明降采样输入起点（start_idx=76，对应降采样第77点）
│       ├── data_<Channel>.svg # 各通道预测图
│       └── data.npy           # 对应偏移的预测数据
│   
├── d1_sub6/                   # 先降噪再降采样的场景
│       ├── config.md          # 说明降采样输入起点（start_idx=76，对应降采样第77点）
│       ├── data_<Channel>.svg # 各通道预测图
│       └── data.npy           # 对应偏移的预测数据

```

### 名词说明
- “本征”：仅采用当前模型 + 当前测试集做的一次示例预测，文件集中在 `本征/` 下。
- “cont”：按照对应 `cont/config.md` 描述的方案，对每个通道分别进行连续预测，输出单通道 `.npy` 与 `.svg`。
- “off0~off5”：降采样或降噪+降采样场景中的不同起始偏移版本。只有off1中有预测结果，因为我们要研究 `cont/config.md` 中的方案的结果，没有必要预测其他偏移量数据集。

### 结果表现与 PPT 展示指引
**PPT上，最好展示"Red", "Violet", "Yellow"三个通道的预测结果。**
#### raw, d1
raw 和 d1 的预测结果较差(raw/本征，d1/本征)
在测试数据集上的误差：
raw: MSE = 1.278088
d1: MSE = 2.813083

我们发现d1的预测结果反而比raw更差。
但是，我们观察这两个模型在训练数据集上的结果：
1. raw: epochs数：83，MSE = 0.137593
2. d1: epochs数：99，MSE = 0.034773
可以看到d1在训练集上表现更好，因为d1更加友好的数据集降低了模型“预测”噪声的能力，从而导致在噪声较大的测试集上表现更差。

#### sub6, d1_sub6
sub6 和 d1_sub6 的预测结果较好(sub6/off1, d1_sub6.off1)，且 d1_sub6 (0.004258)与sub6(MSE = 0.004132)在各自测试数据集上评测时MSE几乎相同。
与 raw 和 d1 的结果对比，我们发现**降采样后的数据集更容易预测，说明降采样有效地去除了高频噪声成分，从而提升了预测能力。**
并且降采样对原始数据集并无破坏。

#### raw, d1 在 cont 方案下的表现
我们硬生生用在 raw 和 d1 上训练的模型去预测降采样数据集，即`cont/config.md`中的方案，因此得到了raw/cont, d1/cont的结果，预测表现与 sub6/d1_sub6 持平。说明这两种模型虽然在预测局部变化时表现较差，但是居然能够捕捉到长周期变化趋势，从而在降采样数据集上也能有不错的预测效果。MSE：
raw：
|Blue| Green| Infrared | Red | Transparent | Ultraviolet | Violet |  Yellow |
|----|------|----------|-----|-------------|-------------|--------|----------|
|0.004081 | 0.001323 | 0.001672 | 0.002620 | 0.003235 | 0.000273 | 0.000502 | 0.001178 | 
d1:
|Blue| Green| Infrared | Red | Transparent | Ultraviolet | Violet |  Yellow |
|----|------|----------|-----|-------------|-------------|--------|----------|
| 0.002543 | 0.000327 | 0.000437 | 0.004881 | 0.003373| 0.002825| 0.000630 | 0.000399 |

平均下来，d1的表现优于raw，并且这两种方案在MSE误差上的结果都远优于sub6, d1_sub6的结果（从预测曲线上来看差不多），原因可能是这种方案执行的是单步预测，而sub6, d1_sub6执行的是10步预测，由于Auto-Regressive模型的误差会随着预测步数增加而累积，从而导致多步预测的误差更大。

#### sub6/off1 by d1_sub6 
我们试图验证主动限幅和滑动平均两种破坏原始数据集的数据增强方式训练出来的模型对原始噪声较大的数据也能有很好的预测能力，因此我们用在数据集`d1_sub6`上训练的模型去预测`sub6/off1`的数据集，结果保存在`sub6/off1_by_d1_sub6`目录下，结果与`d1_sub6/off1`稍微要好一点。
MSE如下：
- sub6: MSE = 0.004132
- sub6 by d1_sub6: MSE = 0.003689
说明我们的两种降噪算法虽然破坏了原始数据，不使用降采样直接预测的话不如原始数据集的结果。但是一旦降采样因子介入后，模型的预测能力会略优于在只用降采样降噪后的数据集上训练的模型的预测能力。具体原因待分析。

